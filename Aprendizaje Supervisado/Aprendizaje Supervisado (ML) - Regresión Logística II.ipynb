{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> float64\n",
      "(178, 14)\n"
     ]
    }
   ],
   "source": [
    "#La base de datos \"wine\" contiene muestras de 3 clases de vinos. Cada una de las observaciones tiene 13 atributos (ver http://archive.ics.uci.edu/ml/datasets/Wine)\n",
    "#Encuentra la combinación de estrategia de pre-procesamiento + parámetro de regularización C del clasificador logístico\n",
    "#con la que se obtenga el mejor acierto de clasificación. Se deben contemplar al menos 5 parámetros de C (suficientemente separados entre sí) \n",
    "#y 3 estrategias de pre-procesamiento. \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import genfromtxt #librería para leer archivos de texto\n",
    "#Primero debes ingresar a la URL del párrafo superior y descargar la base de datos. La encontrarás como wine.data.\n",
    "#Una vez descargada, guárdala en la misma ruta del notebook\n",
    "\n",
    "\n",
    "data = genfromtxt('wine.data', delimiter=',') #almacenamos la base de datos en la variable data\n",
    "print(type(data),data.dtype) #nos muestra el tipo de varible que es data y el tipo de datos que contiene\n",
    "print(data.shape)\n",
    "#debemos tener en cuenta que para esta base de datos la primera columna es la etiqueta y las siguientes 13 son los \n",
    "#atributos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ejercicio 1 **\n",
    "\n",
    "Desarrolla un código que almacene en la variable X la matriz de observaciones (para este caso sería una matriz de 178x13) y\n",
    "en Y las etiquetas (vector de 178 posiciones). Adicionalmente debes convertir el vector de etiquetas en un vector de números enteros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n"
     ]
    }
   ],
   "source": [
    "#aquí está el espacio para desarrollar el ejericicio 1\n",
    "\n",
    "observaciones =[]\n",
    "#etiquetas2 = []\n",
    "etiquetas = []\n",
    "\n",
    "#for x in range (0,177):\n",
    "#    etiquetas2.append(data[x,0])\n",
    "etiquetas = data[:,0]   \n",
    "#print (etiquetas2)\n",
    "#print (etiquetas)\n",
    "#print (etiquetas.shape)\n",
    "observaciones = data[:,1:]\n",
    "#print(observaciones)\n",
    "#print(etiquetas.dtype)\n",
    "X = observaciones\n",
    "Y = etiquetas.astype(int)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Ejercicio 2 **\n",
    "\n",
    "1. Divide la matriz de observaciones en 80% para entrenamiento y 20% para validación\n",
    "2. Genera las 3 estrategias de preprocesamiento y aplícalas correctamente a las matrices X_train y X_test\n",
    "3. Instancia los 5 clasificadores (1 para cada valor de C)\n",
    "4. Entrena cada clasificador para cada una de las estrategias de preprocesamiento\n",
    "5. Valida los clasificadores con cada uno de los X_test\n",
    "6. Concluye. ¿Cuál fue la mejor combinación de C y preprocesamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(142, 13)\n",
      "36 13\n"
     ]
    }
   ],
   "source": [
    "#espacio para solucionar el ejercicio 2\n",
    "#punto 1\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.2, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(np.shape(X_test)[0], np.shape(X_test)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#punto 2\n",
    "#Preprocesamiento por remocion de la media para X_train y X_test\n",
    "def remocion_train_test(X_train,X_test):\n",
    "    media_train = X_train.mean(axis = 0) # calculamos la media del conjunto de entrenamiento\n",
    "    desviacion_train = X_train.std(axis = 0) # calculamos la desviacion estándar del conjunto de entrenamiento\n",
    "    \n",
    "    X_train_rem = (X_train - media_train)/desviacion_train # preprocesamos la matriz de entrenamiento\n",
    "    X_test_rem = (X_test - media_train)/desviacion_train # preprocesamos la matriz de validacion o test\n",
    "    \n",
    "    return X_train_rem, X_test_rem\n",
    "\n",
    "#Preprocesamiento por escalamiento para X_train y X_test\n",
    "def escalamiento_train_test(X_train,X_test):\n",
    "    minimo_train = X_train.min(axis=0)\n",
    "    maximo_train = X_train.max(axis=0)\n",
    "    \n",
    "    X_train_preprocesado = (X_train - minimo_train)/(maximo_train - minimo_train)\n",
    "    X_test_preprocesado = (X_test - minimo_train)/(maximo_train - minimo_train)\n",
    "    \n",
    "    return X_train_preprocesado, X_test_preprocesado\n",
    "\n",
    "#Preprocesamiento por normalizacion L1 para X_train y X_test\n",
    "def normalizar_train_test(X_train,X_test): #definimos la función para la norma L1\n",
    "    norma = np.linalg.norm(X_train,ord=1,axis=1) #calculamos el valor de la norma con la función np.linalg.norm. El orden \n",
    "                                            #indica qué tipo de norma es y \"axis=1\" nos dice que la calculamos sobre las filas\n",
    "    filas = np.shape(X_train)[0]\n",
    "    columnas = np.shape(X_train)[1]\n",
    "    norma1 = np.repeat(norma,columnas) #como tenemos 13 normas en total (1 por cada fila), repetimos cada una tres veces\n",
    "    norma1 = np.resize(norma,(filas,columnas)) #reorganizamos las normas para que nos queden del mismo tamaño de X_train\n",
    "    X_train_normalizado = X_train/norma1 #dividimos punto a punto los datos entre la norma\n",
    "    \n",
    "    filas = np.shape(X_test)[0]\n",
    "    columnas = np.shape(X_test)[1]\n",
    "    norma2 = np.repeat(norma,columnas)\n",
    "    norma2 = np.resize(norma,(filas,columnas)) #reorganizamos las normas para que nos queden del mismo tamaño de X_test\n",
    "    X_test_normalizado = X_test/norma2 #dividimos punto a punto los datos entre la norma\n",
    "    \n",
    "    return X_train_normalizado, X_test_normalizado #retornamos la matriz normalizada\n",
    "\n",
    "#X_train y X_test usando preprocesamiento por remocion de la media\n",
    "X_train_remocion, X_test_remocion = remocion_train_test(X_train, X_test)\n",
    "print(type(X_train_remocion))\n",
    "\n",
    "#X_train y X_test usando preprocesamiento por escalamiento\n",
    "X_train_escalamiento, X_test_escalamiento = escalamiento_train_test(X_train, X_test)\n",
    "\n",
    "#X_train y X_test usando preprocesamiento por normalización L1\n",
    "X_train_normalizar, X_test_normalizar = normalizar_train_test(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#clasificadores para escalamiento\\nLogisticRegression(C=10.0, random_state = 0) \\nLogisticRegression(C=269.0, random_state = 0)\\nLogisticRegression(C=670.0, random_state = 0)\\nLogisticRegression(C=700.0, random_state = 0)\\n LogisticRegression(C=1000.0, random_state = 0)\\n\\n#clasficadores para normalizar\\nLogisticRegression(C=10.0, random_state = 0) \\nLogisticRegression(C=269.0, random_state = 0)\\nLogisticRegression(C=670.0, random_state = 0)\\nLogisticRegression(C=700.0, random_state = 0)\\nLogisticRegression(C=1000.0, random_state = 0)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto 3\n",
    "#clasificadores para normalizar, escalamiento y remocion respectivamente\n",
    "clasificador11 = clasificador6 = clasificador1 = LogisticRegression(C=10.0, random_state = 0) \n",
    "clasificador12 = clasificador7 = clasificador2 = LogisticRegression(C=269.0, random_state = 0)\n",
    "clasificador13 = clasificador8 = clasificador3 = LogisticRegression(C=670.0, random_state = 0)\n",
    "clasificador14 = clasificador9 = clasificador4 = LogisticRegression(C=700.0, random_state = 0)\n",
    "clasificador15 = clasificador10 = clasificador5 = LogisticRegression(C=1000.0, random_state = 0)\n",
    "'''\n",
    "#clasificadores para escalamiento\n",
    "LogisticRegression(C=10.0, random_state = 0) \n",
    "LogisticRegression(C=269.0, random_state = 0)\n",
    "LogisticRegression(C=670.0, random_state = 0)\n",
    "LogisticRegression(C=700.0, random_state = 0)\n",
    " LogisticRegression(C=1000.0, random_state = 0)\n",
    "\n",
    "#clasficadores para normalizar\n",
    "LogisticRegression(C=10.0, random_state = 0) \n",
    "LogisticRegression(C=269.0, random_state = 0)\n",
    "LogisticRegression(C=670.0, random_state = 0)\n",
    "LogisticRegression(C=700.0, random_state = 0)\n",
    "LogisticRegression(C=1000.0, random_state = 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=0,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#punto 4\n",
    "#entrenamiento para remocion\n",
    "clasificador1.fit(X_train_remocion,y_train)\n",
    "clasificador2.fit(X_train_remocion,y_train)\n",
    "clasificador3.fit(X_train_remocion,y_train)\n",
    "clasificador4.fit(X_train_remocion,y_train)\n",
    "clasificador5.fit(X_train_remocion,y_train)\n",
    "\n",
    "#entrenamiento para escalamiento\n",
    "clasificador6.fit(X_train_escalamiento,y_train)\n",
    "clasificador7.fit(X_train_escalamiento,y_train)\n",
    "clasificador8.fit(X_train_escalamiento,y_train)\n",
    "clasificador9.fit(X_train_escalamiento,y_train)\n",
    "clasificador10.fit(X_train_escalamiento,y_train)\n",
    "\n",
    "#entrenamiento para normalizar\n",
    "clasificador11.fit(X_train_normalizar,y_train)\n",
    "clasificador12.fit(X_train_normalizar,y_train)\n",
    "clasificador13.fit(X_train_normalizar,y_train)\n",
    "clasificador14.fit(X_train_normalizar,y_train)\n",
    "clasificador15.fit(X_train_normalizar,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Punto 5\n",
    "#Realizamos el test/validación de los datos y  \n",
    "#comparamos las etiquetas de la base de datos con las que encontró el clasificador para así fijar el error de clasificación\n",
    "\n",
    "#Validación para remocion\n",
    "y_pred1 = clasificador1.predict(X_test_remocion)\n",
    "y_pred2 = clasificador2.predict(X_test_remocion)\n",
    "y_pred3 = clasificador3.predict(X_test_remocion)\n",
    "y_pred4 = clasificador4.predict(X_test_remocion)\n",
    "y_pred5 = clasificador5.predict(X_test_remocion)\n",
    "\n",
    "#Validación para escalamiento\n",
    "y_pred6 = clasificador6.predict(X_test_escalamiento)\n",
    "y_pred7 = clasificador7.predict(X_test_escalamiento)\n",
    "y_pred8 = clasificador8.predict(X_test_escalamiento)\n",
    "y_pred9 = clasificador9.predict(X_test_escalamiento)\n",
    "y_pred10 = clasificador10.predict(X_test_escalamiento)\n",
    "\n",
    "#Validación para normalizar\n",
    "y_pred11 = clasificador11.predict(X_test_normalizar)\n",
    "y_pred12 = clasificador12.predict(X_test_normalizar)\n",
    "y_pred13 = clasificador13.predict(X_test_normalizar)\n",
    "y_pred14 = clasificador14.predict(X_test_normalizar)\n",
    "y_pred15 = clasificador15.predict(X_test_normalizar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remocion \n",
      "\n",
      "Las muestras mal clasificadas fueron 5\n",
      "Las muestras mal clasificadas fueron 4\n",
      "Las muestras mal clasificadas fueron 4\n",
      "Las muestras mal clasificadas fueron 4\n",
      "Las muestras mal clasificadas fueron 5\n",
      "\n",
      "Escalamiento \n",
      "\n",
      "Las muestras mal clasificadas fueron 18\n",
      "Las muestras mal clasificadas fueron 15\n",
      "Las muestras mal clasificadas fueron 16\n",
      "Las muestras mal clasificadas fueron 16\n",
      "Las muestras mal clasificadas fueron 16\n",
      "\n",
      "Normalizacion L1 \n",
      "\n",
      "Las muestras mal clasificadas fueron 9\n",
      "Las muestras mal clasificadas fueron 8\n",
      "Las muestras mal clasificadas fueron 7\n",
      "Las muestras mal clasificadas fueron 7\n",
      "Las muestras mal clasificadas fueron 5\n"
     ]
    }
   ],
   "source": [
    "#punto 6\n",
    "\n",
    "print('Remocion \\n')\n",
    "\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred1).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred2).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred3).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred4).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred5).sum())\n",
    "\n",
    "print('\\nEscalamiento \\n')\n",
    "\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred6).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred7).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred8).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred9).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred10).sum())\n",
    "\n",
    "print('\\nNormalizacion L1 \\n')\n",
    "\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred11).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred12).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred13).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred14).sum())\n",
    "print('Las muestras mal clasificadas fueron %d' % (y_test != y_pred15).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#punto 6\n",
    "print('La mejor combinación de método de preprocesamiento con combinaciones de C fue Remoción de la media')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
