{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparación perceptrón\n",
    "\n",
    "¿Recuerdas el ejercicio del parcial? Vamos a repetirlo pero utilizando *k*-NN y perceptrón para comparar su desempeño. Ten en cuenta las recomendaciones realizadas en el parcial (principalmente la de el pre-procesamiento de las muestras del archivo $\\verb|Test-txt|$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El sistema experto que generes debe cumploir con las siguientes condiciones:\n",
    "\n",
    "1. Se debe hacer una partición de entrenamiento y validación para probar el sistema desarrollado.\n",
    "2. Tener una etapa de preprocesamiento de las observaciones.\n",
    "3. ***Comparar el desempeño del perceptrón con el desempeño de *k*-NN (utilizando la librería de python)***\n",
    "4. Después de tener el sistema entrenado y validado se debe dar la información  de calidad para las 19 muestras de café de las que no se tiene conocimiento.\n",
    "5. Cualquier tipo de información adicional que crea requerir la debe suponer. Cada supuesto debe estar perfectamente justificado de forma explícita en formato de comentarios dentro del código\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 5)\n",
      "(100, 4)\n",
      "(20, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from numpy import genfromtxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from sklearn import neighbors, datasets\n",
    "import neurolab as nl\n",
    "\n",
    "#Se cargan los datos de los archivos de texto a cada una de sus variables:\n",
    "# cafe.txt en cafe, expertos.txt en expertos y test.txt en test\n",
    "\n",
    "cafe = genfromtxt('cafe.txt', delimiter=',')\n",
    "print(cafe.shape)\n",
    "\n",
    "expertos = genfromtxt('expertos.txt', delimiter=',') \n",
    "print(expertos.shape)\n",
    "\n",
    "test = genfromtxt('test.txt', delimiter=',')\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definiciones de funciones\n",
    "\n",
    "#Hacemos la función para la remoción de la media, nuestra idea es que la desviación estándar sea 1 y la media sea 0\n",
    "def Remocion(X): #definimos la función\n",
    "    X = X - X.mean(axis=0) # a los datos les restamos el valor de la media\n",
    "    X = X/X.std(axis=0) #al resultado lo dividimos por la desviación estándar\n",
    "    return X #retornamos los datos normalizamos\n",
    "\n",
    "#Método para elegir y retornar una etiqueta para un café usando la regla mayoritaria en las calificaciones de los expertos\n",
    "def regla_mayoritaria_vector(vector):\n",
    "    #etiqueta es un vector de dos posiciones, donde el primer valor es la etiqueta que más se repite en el vector\n",
    "    # y el segundo valor es cuantas veces está en el vector\n",
    "    etiqueta = np.array([0,0]) \n",
    "    for i in range(len(np.unique(vector))): \n",
    "        #contador es el numero de veces que una etiqueta se encuentra en el vector\n",
    "        contador = np.shape(np.where(vector == np.unique(vector)[i]))[1]\n",
    "        if etiqueta[1] < contador: #Si el contador es mayor a la etiqueta anterior o por defecto, se guardan los datos\n",
    "            etiqueta[1] = contador #Numero de veces que se encontró\n",
    "            etiqueta[0] = np.unique(vector)[i] #Cual etiqueta es\n",
    "    #En caso de encontrar un número igual de ocurrencias para dos etiquetas, se tomará la primera etiqueta encontrada\n",
    "    return etiqueta\n",
    "\n",
    "#Método para elegir y retornar la etiqueta para todos las muestras de café usando la regla mayoritaria\n",
    "def regla_mayoritaria(matriz):\n",
    "    filas = np.shape(matriz)[0]\n",
    "    etiquetas = np.array([]) #Se declara un array para agrupar todas las etiquetas\n",
    "    for i in range(filas):\n",
    "        etiqueta = regla_mayoritaria_vector(matriz[i]) #Obtengo la etiqueta para cada fila (muestra de café)\n",
    "        etiquetas = np.append(etiquetas,etiqueta[0]) #La añado al array temporal\n",
    "    return etiquetas\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Punto 2\n",
    "#Le aplico remoción de la media a todos las observaciones de las muestras de café y las muestras en test.txt\n",
    "X = Remocion(cafe)\n",
    "test_remocion = Remocion(test)\n",
    "\n",
    "#Usando la regla mayoritaria hallo la etiqueta para cada muestra de café\n",
    "#y = regla_mayoritaria(expertos)\n",
    "y = expertos\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70, 5) \n",
      " (30, 5)\n",
      "(70, 4) \n",
      " (30, 4)\n"
     ]
    }
   ],
   "source": [
    "#Punto 1\n",
    "#Divido la matriz de observaciones en 70% para entrenamiento y 30% para validación\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=0)\n",
    "print(X_train.shape, '\\n', X_test.shape)\n",
    "print(y_train.shape, '\\n', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=9, p=2,\n",
       "           weights='distance')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Punto 3 \n",
    "#Clasificador KNN usando librería de python\n",
    "y_train_KNN = regla_mayoritaria(y_train)\n",
    "y_test_KNN = regla_mayoritaria(y_test)\n",
    "NN = 9 #definimos el número de vecinos (en lo posible elegir números impares)\n",
    "clasificador_KNN = neighbors.KNeighborsClassifier(NN, weights = 'distance') #instanciamos el clasificador\n",
    "clasificador_KNN.fit(X_train,y_train_KNN) #entrenamos el clasificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70,)\n",
      "(70, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_train[:,0].shape)\n",
    "y_train_stack = np.vstack(y_train[:,0])\n",
    "print(y_train_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6552544681886114 1.506188702633783\n",
      "-1.4206026640535003 1.0929682080840482\n",
      "-1.179744511939493 1.8173073531860975\n",
      "-1.4206026640535003 0.8863579608091808\n",
      "-1.224036862008721 2.365010055045843\n",
      "Epoch: 20; Error: 15.0;\n",
      "Epoch: 40; Error: 16.5;\n",
      "Epoch: 60; Error: 17.5;\n",
      "Epoch: 80; Error: 11.0;\n",
      "Epoch: 100; Error: 14.5;\n",
      "The maximum number of train epochs is reached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.02251978,  0.04375428, -0.09637135,  0.09898697,  0.00766844],\n",
       "       [ 0.23391514,  0.06528416,  0.02292914, -0.15117672, -0.01775485],\n",
       "       [-0.12228483,  0.11633082, -0.01982595,  0.07716893,  0.06459448],\n",
       "       [-0.02929993,  0.05972806, -0.02551513, -0.10016465,  0.00635582]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perceptrón\n",
    "#y_train_stack = np.vstack(y_train)\n",
    "#y_test_stack = np.vstack(y_test)\n",
    "\n",
    "def minimo_y_maximo(train,test):\n",
    "    minimo = train.min()\n",
    "    if minimo > test.min():\n",
    "        minimo = test.min()\n",
    "    maximo = train.max()\n",
    "    if maximo < test.max():\n",
    "        maximo = test.max()\n",
    "    print(minimo,maximo)\n",
    "    return minimo, maximo\n",
    "\n",
    "#definimos los valores máximos y mínimos que puede tomar cada dimensión\n",
    "# dim1_min, dim1_max, dim2_min, dim2_max = 0,1,0,1\n",
    "#dim1_min, dim1_max = minimo_y_maximo(X_train,X_test)\n",
    "#dim2_min, dim2_max = minimo_y_maximo(y_train_stack,y_test_stack)\n",
    "\n",
    "dim1_min, dim1_max = minimo_y_maximo(X_train[0],X_test[0])\n",
    "dim2_min, dim2_max = minimo_y_maximo(X_train[1],X_test[1])\n",
    "dim3_min, dim3_max = minimo_y_maximo(X_train[2],X_test[2])\n",
    "dim4_min, dim4_max = minimo_y_maximo(X_train[3],X_test[3])\n",
    "dim5_min, dim5_max = minimo_y_maximo(X_train[4],X_test[4])\n",
    "\n",
    "#Dado que los datos están seprados en dos clases, solo necesitamos un bit\n",
    "#para representar la salida. Por tanto la capa de salida solo tendrá una neurona\n",
    "\n",
    "#Número de neuronas en la capa de salida\n",
    "num_output = y_train.shape[1]\n",
    "#tenemos un conjunto de datos de dos dimensiones, definimos un perceptron\n",
    "# con dos neuronas a la entrada y le asignamos una a cada dimensión\n",
    "dim1 = [dim1_min, dim1_max]\n",
    "dim2 = [dim2_min, dim2_max]\n",
    "dim3 = [dim3_min, dim3_max]\n",
    "dim4 = [dim4_min, dim4_max]\n",
    "dim5 = [dim5_min, dim5_max]\n",
    "\n",
    "#perceptron = nl.net.newp([dim1,dim2], num_output)\n",
    "perceptron = nl.net.newp([dim1,dim2,dim3,dim4,dim5], num_output)\n",
    "#entrenamos el perceptron con el conjunto de entrenamiento \n",
    "# lr es la tasa de aprendizaje, e indica que tan rápico o que tan lento se actualizan los pasos\n",
    "#epochs indica el número de pasadas por todo el conjunto de entrenamiento\n",
    "progreso_error = perceptron.train(X_train, y_train, epochs=100, show=20, lr=0.03)\n",
    "perceptron.layers[0].np['w'] #con esta instrucción conocemos los pesos para la capa de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El acierto de clasificación del clasificador KNN (python) es del  90.0 %\n",
      "Las muestras mal clasificadas del clasificador KNN fueron 3\n",
      "El acierto de clasificación es:  83.33333333333334 %\n",
      "100 (30, 4) (30, 4) 30\n",
      "[[0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [1. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]] [[0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 1.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Punto 3\n",
    "#Validamos el acierto de clasificación del clasificador KNN\n",
    "y_pred_KNN = clasificador_KNN.predict(X_test) #realizamos la predicción de la etiqueta para el conjunto de validación\n",
    "acc_KNN = 100.0*(y_test_KNN == y_pred_KNN).sum()/X_test.shape[0] #calculamos el acierto de clasificación\n",
    "print('El acierto de clasificación del clasificador KNN (python) es del ',acc_KNN , '%') #imprimimos el acierto de clasificacion\n",
    "print('Las muestras mal clasificadas del clasificador KNN fueron %d' % (y_test_KNN != y_pred_KNN).sum())\n",
    "\n",
    "#vamos a validar con el mismo conjunto de entrenamiento. Recuerda que la validación se hace normalmente con el conjunto de test\n",
    "#Validamos el acierto de clasficiación del perceptrón    \n",
    "y_pred_perceptron = perceptron.sim(X_test)\n",
    "print('El acierto de clasificación es: ', (y_test==y_pred_perceptron).sum()/(np.shape(y_test)[0]*np.shape(y_test)[1])*100, '%')\n",
    "print((y_test == y_pred_perceptron).sum(), y_pred_perceptron.shape, y_test.shape, len(y_test))\n",
    "print(y_pred_perceptron, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las predicciones para cada uno de las muestras en test.txt usando el clasificador KNN(python) es: \n",
      "\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[[0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 0. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [1. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 1. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 1. 1.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 1. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "test_remocion = Remocion(test)\n",
    "\n",
    "y_pred_test_KNN = clasificador_KNN.predict(test_remocion) \n",
    "print(\"Las predicciones para cada uno de las muestras en test.txt usando el clasificador KNN(python) es: \\n\")\n",
    "print(y_pred_test_KNN)\n",
    "\n",
    "y_pred_perceptron_test = perceptron.sim(test_remocion)\n",
    "print(y_pred_perceptron_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
